{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b02911a8-e2c1-4440-88dc-50dd668917f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0807c87a-17d6-4221-91d8-a9853984f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_data(subreddit, limit, since, until):\n",
    "    \"\"\"\n",
    "    Connect to API and pull data.\n",
    "    \n",
    "    Args:\n",
    "        subreddit (string): The name of subreddit\n",
    "        limit (number): The number of submisison returned\n",
    "        since (string): The start epoch time\n",
    "        until (string): The end epoch time\n",
    "        \n",
    "    Returns:\n",
    "        list: The list of each submission with 'selftext', 'title' and 'subreddit'\n",
    "    \"\"\"\n",
    "    \n",
    "    url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "    \n",
    "    params = {\n",
    "        'subreddit': subreddit,\n",
    "        'limit': limit,\n",
    "        'since': since,\n",
    "        'until': until\n",
    "    }\n",
    "    \n",
    "    res = requests.get(url, params)\n",
    "    if res.status_code == 200:\n",
    "        data = res.json()\n",
    "           \n",
    "        return [{'selftext': row['selftext'], 'title': row['title'], 'subreddit': row['subreddit']} for row in data['data']]\n",
    "            \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b4724db-2dc4-4dbd-9bff-de4835188c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(subreddit):\n",
    "    \"\"\"\n",
    "    Combine data from each pull and transform it into a single pandas dataframe.\n",
    "    \n",
    "    Args:\n",
    "        subreddit (string): The name of subreddit\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    cur_time = datetime(2023, 4, 19, 19, 19, 19)\n",
    "    epoch_time = datetime.timestamp(cur_time)\n",
    "    epoch_time_interval = 24 * 60 * 60 * 60\n",
    "    time_interval = [(str(int(epoch_time - (i + 1) * epoch_time_interval)), str(int(epoch_time - i * epoch_time_interval - 360))) for i in range(12)]\n",
    "    \n",
    "    remain_interval = [*time_interval]\n",
    "    \n",
    "    all_data = []\n",
    "    while remain_interval:\n",
    "        for since, until in remain_interval:\n",
    "            cur_data = gather_data(subreddit, 500, since, until)\n",
    "            if cur_data:\n",
    "                all_data.extend(cur_data)\n",
    "                remain_interval.remove((since, until))\n",
    "\n",
    "            time.sleep(15)\n",
    "        print(remain_interval)\n",
    "    pd.DataFrame(all_data).to_csv(f'../data/{subreddit}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c76a9f7e-04da-4bf9-b8e8-9598d45a689c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1671589159', '1676772799'), ('1661221159', '1666404799'), ('1650853159', '1656036799'), ('1640485159', '1645668799'), ('1635301159', '1640484799'), ('1624933159', '1630116799')]\n",
      "[('1661221159', '1666404799'), ('1640485159', '1645668799'), ('1624933159', '1630116799')]\n",
      "[('1640485159', '1645668799')]\n",
      "[]\n",
      "[('1671589159', '1676772799'), ('1661221159', '1666404799'), ('1650853159', '1656036799'), ('1640485159', '1645668799'), ('1630117159', '1635300799'), ('1619749159', '1624932799')]\n",
      "[('1661221159', '1666404799'), ('1640485159', '1645668799'), ('1619749159', '1624932799')]\n",
      "[('1640485159', '1645668799')]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over two subreddits and invoke the function to collect and generate the data\n",
    "for sub in ['SoftwareEngineering', 'datascience']:\n",
    "    create_data(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6996fb0-3895-49b6-99f7-5c27afdcb5e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
